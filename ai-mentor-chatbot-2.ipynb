{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12701169,"sourceType":"datasetVersion","datasetId":8022688}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:00.763319Z","iopub.execute_input":"2025-08-07T20:59:00.764030Z","iopub.status.idle":"2025-08-07T20:59:00.771484Z","shell.execute_reply.started":"2025-08-07T20:59:00.764005Z","shell.execute_reply":"2025-08-07T20:59:00.770866Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ===============================\n# AI Educational Chatbot with RAG\n## ===============================\n### This system provides:\n#### 1. Multi-source knowledge retrieval (PDFs, Wikipedia)\n#### 2. Gradio web interface\n#### 3. Performance evaluation\n## ===============================","metadata":{}},{"cell_type":"code","source":"# 1. Install required packages\n\n!pip install langchain langchain-community gradio sentence-transformers \n!pip install transformers pypdf faiss-cpu nltk chromadb PyMuPDF wikipedia sacrebleu\n\n# 2. Import core libraries\n\nimport re\nimport fitz \nfrom typing import List, Dict, Tuple\nfrom pypdf import PdfReader\nfrom googlesearch import search\nimport wikipedia\nimport torch\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.docstore.document import Document\nfrom langchain.prompts import ChatPromptTemplate\n\nfrom transformers import MarianMTModel, MarianTokenizer, pipeline\nfrom sacrebleu import corpus_bleu\nimport gradio as gr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:00.788840Z","iopub.execute_input":"2025-08-07T20:59:00.789038Z","iopub.status.idle":"2025-08-07T20:59:08.371571Z","shell.execute_reply.started":"2025-08-07T20:59:00.789023Z","shell.execute_reply":"2025-08-07T20:59:08.370625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## - PDF Processing :","metadata":{}},{"cell_type":"code","source":"# 3. PDF Processing\ndef clean_text(text: str) -> str:\n    \"\"\"Clean extracted PDF text\"\"\"\n    # Remove headers/footers\n    text = re.sub(r'Page \\d+|Chapter \\d+', '', text)\n    # Remove bullet points and special chars\n    text = re.sub(r'[\\u2022\\u2023\\u25CF•–·●▪►]', '', text)\n    # Normalize whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    text = text.split('\\n')\n    lines = [line.strip() for line in text if line.strip() != '']\n    text = ' '.join(lines)\n    text = re.sub(r'[\\u2022\\u2023\\u25CF\\u25A0•–·●▪►]', '', text)\n    text = re.sub(r'\\s+', ' ', text) \n    text = re.sub(r' +([,!?؛:])', r'\\1', text)\n    text = text.strip()\n    return text\n\ndef process_pdf(file_path: str, skip_pages: int = 20) -> str:\n    \"\"\"Extract and clean text from PDF\"\"\"\n    doc = fitz.open(file_path)\n    full_text = \"\"\n\n    for page_num in range(skip_pages, len(doc)):\n        page = doc[page_num]\n        full_text += page.get_text()\n    \n    doc.close()\n    return clean_text(full_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:08.373156Z","iopub.execute_input":"2025-08-07T20:59:08.373456Z","iopub.status.idle":"2025-08-07T20:59:08.380391Z","shell.execute_reply.started":"2025-08-07T20:59:08.373433Z","shell.execute_reply":"2025-08-07T20:59:08.379837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## - Knowledge Base :","metadata":{}},{"cell_type":"code","source":"def process_pdfs_and_create_vectorstore(pdf_folder: str, skip_pages: int = 20):\n    \"\"\"Process PDFs from a folder and return a Chroma vectorstore\"\"\"\n    embedding_model = HuggingFaceEmbeddings(\n        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n    )\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=50,\n        chunk_overlap=5,\n        length_function=len\n    )\n    documents = []\n\n    for filename in os.listdir(pdf_folder):\n        if filename.endswith(\".pdf\"):\n            file_path = os.path.join(pdf_folder, filename)\n            text = process_pdf(file_path, skip_pages=skip_pages)\n\n            chunks = text_splitter.split_text(text)\n            for chunk in chunks:\n                documents.append(Document(\n                    page_content=chunk,\n                    metadata={\"source\": filename}\n                ))\n\n    if documents:\n        vectorstore = Chroma.from_documents(\n            documents=documents,\n            embedding=embedding_model\n        )\n        return vectorstore\n    else:\n        return None\n\ndef query_vectorstore(vectorstore, question: str, k: int = 3) -> List[Document]:\n    \"\"\"Query the vector store for relevant documents\"\"\"\n    if vectorstore is None:\n        return []\n    return vectorstore.similarity_search(question, k=k)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:08.381046Z","iopub.execute_input":"2025-08-07T20:59:08.381301Z","iopub.status.idle":"2025-08-07T20:59:08.403598Z","shell.execute_reply.started":"2025-08-07T20:59:08.381278Z","shell.execute_reply":"2025-08-07T20:59:08.403079Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## - Load Question Answering model :","metadata":{}},{"cell_type":"code","source":"# pip install -q transformers\nfrom transformers import pipeline\n\ncheckpoint = \"google/flan-t5-large\"\n\nmodel = pipeline('text2text-generation', model = checkpoint)\n\ninput_prompt = \"\"\"System Prompt:\n\nYou are an expert educational chatbot specialized in answering questions based strictly on provided study materials.\n\nStrict Rules:\nLanguage: Respond ONLY in English, regardless of the input language.\n\nSources Priority:\n\nFirst: Use the provided PDF documents as the main and preferred source.\n\nSecond: Refer to verified English Wikipedia knowledge if the PDFs do not contain the answer.\n\nThird: Use a general web search as a last fallback.\n\nTone & Style: Maintain a professional, academic tone appropriate for educational settings.\n\nAccuracy Guidelines:\n\nIf uncertain or unable to verify, respond with: “I couldn't verify this from my sources.”\n\nNever hallucinate or fabricate information.\n\nCite your source explicitly when possible.\n\nResponse Format (Always Follow This Template):\nless\n[Source: PDFs/Wikipedia/Web]  \n[Confidence: High/Medium/Low]  \n\nAnswer: [Concise and accurate response goes here]\nExamples of Interactions (Follow Format Exactly):\nUser: What is Artificial intelligence?\nBot:\n[Source: PDFs]\n[Confidence: High]\nAnswer: Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, especially computer systems.\n\nUser: Explain Gradient Descent\nBot:\n[Source: Wikipedia]\n[Confidence: Medium]\nAnswer: Gradient descent is an optimization algorithm used to minimize the cost function in machine learning by iteratively moving in the direction of the steepest descent as defined by the negative of the gradient.\n\nUser: What’s ML?\nBot:\n[Source: PDFs]\n[Confidence: High]\nAnswer: Machine learning (ML) is a subset of artificial intelligence that focuses on the development of algorithms that enable computers to learn from and make predictions or decisions based on data.\n\n\"\"\"\ngenerated_text = model(input_prompt, max_length=512, do_sample=True)[0]['generated_text']\n\nprint(\"Response :\" + generated_text)\n\n\ndef generate_from_prompt(prompt: str, system_prompt: str = None, max_length: int = 200) -> str:\n    \"\"\"Generate text based on given prompt and optional system prompt\"\"\"\n    if not prompt.strip():\n        return \"\"\n    \n    try:\n        full_prompt = f\"{system_prompt}\\n{prompt}\" if system_prompt else prompt\n        result = generation_model(\n            full_prompt,\n            max_length=max_length,\n            do_sample=True,\n            top_k=4,\n            top_p=0.95\n        )\n        return result[0][\"generated_text\"]\n    except Exception as e:\n        print(f\"Generation error: {e}\")\n        return \"\"\n\ndef generate_from_wikipedia(topic: str, system_prompt: str = None) -> str:\n    \"\"\"Fallback: Generate text using a Wikipedia summary\"\"\"\n    try:\n        wikipedia.set_lang(\"en\")\n        summary = wikipedia.summary(topic, sentences=3)\n        return generate_from_prompt(f\"Expand on this: {summary}\", system_prompt=system_prompt)\n    except Exception as e:\n        print(f\"Wikipedia error: {e}\")\n        return \"\"\n\ndef get_google_search_link(query: str) -> str:\n    \"\"\"Fallback: Get a Google search link for a query\"\"\"\n    try:\n        return next(search(query, num=1, stop=1, pause=2))\n    except Exception as e:\n        print(f\"Google search error: {e}\")\n        return \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:08.405387Z","iopub.execute_input":"2025-08-07T20:59:08.405579Z","iopub.status.idle":"2025-08-07T20:59:11.129397Z","shell.execute_reply.started":"2025-08-07T20:59:08.405566Z","shell.execute_reply":"2025-08-07T20:59:11.128635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## - Evaluation :","metadata":{}},{"cell_type":"code","source":"from sacrebleu.metrics import BLEU\nbleu_metric = BLEU()  # Create a BLEU scorer instance\n\ndef calculate_bleu(predictions: List[str], references: List[str]) -> float:\n    \"\"\"Compute BLEU score for answer quality\"\"\"\n    # SacreBLEU expects a list of hypotheses and a list of reference sets\n    return bleu_metric.corpus_score(predictions, [references]).score\n\ndef calculate_exact_match(predictions: List[str], references: List[str]) -> float:\n    \"\"\"Compute exact match percentage\"\"\"\n    matches = sum(1 for p, r in zip(predictions, references) if p.lower().strip() == r.lower().strip())\n    return matches / len(predictions) if predictions else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:11.130236Z","iopub.execute_input":"2025-08-07T20:59:11.130460Z","iopub.status.idle":"2025-08-07T20:59:11.135930Z","shell.execute_reply.started":"2025-08-07T20:59:11.130442Z","shell.execute_reply":"2025-08-07T20:59:11.135139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"preds = [\"The capital of France is Paris.\", \"Water boils at 100 degrees.\"]\nrefs = [\"The capital of France is Paris.\", \"Water boils at 100°C.\"]\n\nprint(\"BLEU Score:\", calculate_bleu(preds, refs))\nprint(\"Exact Match:\", calculate_exact_match(preds, refs))\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:11.137131Z","iopub.execute_input":"2025-08-07T20:59:11.137589Z","iopub.status.idle":"2025-08-07T20:59:11.157324Z","shell.execute_reply.started":"2025-08-07T20:59:11.137567Z","shell.execute_reply":"2025-08-07T20:59:11.156610Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## - RAG Pipeline :","metadata":{}},{"cell_type":"code","source":"def generate_response(\n    user_question: str,\n    vectorstore,\n    system_prompt: str\n) -> str:\n    \"\"\"Answer generation using vectorstore, Wikipedia, or fallback\"\"\"\n    # 1. ابحث في قاعدة المعرفة\n    relevant_docs = query_vectorstore(vectorstore, user_question)\n    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n    \n    generation_prompt = f\"\"\"{system_prompt}\nUser: {user_question}\nContext: {context}\nBot:\"\"\"\n    \n    answer = generate_from_prompt(generation_prompt, system_prompt)\n    \n    # 2. لو ما فيش إجابة، جرب ويكيبيديا\n    if not answer.strip():\n        answer = generate_from_wikipedia(user_question, system_prompt)\n    \n    # 3. لو برضو مفيش، ارجع برابط بحث\n    if not answer.strip():\n        link = get_google_search_link(user_question)\n        if link:\n            answer = f\"I couldn't find a precise answer. You might find this helpful: {link}\"\n        else:\n            answer = \"Sorry, I couldn't find an answer.\"\n    \n    return answer\n\n\ndef evaluate_system(\n    test_cases: List[Tuple[str, str]],\n    vectorstore,\n    system_prompt: str\n) -> Dict[str, float]:\n    \"\"\"Evaluate chatbot performance on test cases\"\"\"\n    questions = [q for q, _ in test_cases]\n    references = [r for _, r in test_cases]\n    \n    predictions = []\n    for question in questions:\n        response = generate_response(question, vectorstore, system_prompt)\n        predictions.append(response)\n    \n    return {\n        \"bleu\": calculate_bleu(predictions, references),\n        \"exact_match\": calculate_exact_match(predictions, references)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:11.158120Z","iopub.execute_input":"2025-08-07T20:59:11.158438Z","iopub.status.idle":"2025-08-07T20:59:11.182546Z","shell.execute_reply.started":"2025-08-07T20:59:11.158411Z","shell.execute_reply":"2025-08-07T20:59:11.181863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nvectorstore = process_pdfs_and_create_vectorstore(\"/kaggle/input/ai-pdfs/AI\")\n\n\nsystem_prompt = \"\"\"You are an educational assistant. Provide clear and concise answers based on the provided context.\"\"\"\n\nquestion = input(\"ask : \")\nresponse = generate_response(question, vectorstore, system_prompt)\nprint(\"Response:\", response)\n\n\ntest_cases = [\n    (\"What is AI?\", \"AI stands for Artificial Intelligence.\"),\n    (\"What is the capital of France?\", \"The capital of France is Paris.\")\n]\n\nscores = evaluate_system(test_cases, vectorstore, system_prompt)\nprint(\"Evaluation Scores:\", scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T21:00:06.528073Z","iopub.execute_input":"2025-08-07T21:00:06.528347Z","iopub.status.idle":"2025-08-07T21:13:18.326482Z","shell.execute_reply.started":"2025-08-07T21:00:06.528325Z","shell.execute_reply":"2025-08-07T21:13:18.325836Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## - Gradio Interface :","metadata":{}},{"cell_type":"code","source":"\"\"\"# 9. Gradio Interface\nimport gradio as gr\nfrom typing import List, Tuple\n\n\ndef create_chat_interface(pdf_folder: str):\n    \"\"\"Launch interactive web interface\"\"\"\n    chatbot = EducationalChatbot(pdf_folder)\n    \n    def respond(message: str, history: List[Tuple[str, str]]):\n        response = chatbot.generate_response(message)\n        return response\n    \n    demo = gr.Interface(\n        fn=chatbot.generate_response,\n        inputs=gr.Textbox(label=\"Ask your question about AI\", placeholder=\"e.g., What is the difference between AI and ML?\"),\n        outputs=\"text\",\n        title=\"AI Educational Assistant (English)\",\n        description=\"Ask me anything about Artificial Intelligence (English only)\",\n        examples=[\n            \"What is the difference between AI and ML?\",\n            \"Explain neural networks in simple terms\"\n        ],\n        cache_examples=True\n    )\n    \n    return demo\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T20:59:24.756612Z","iopub.status.idle":"2025-08-07T20:59:24.756890Z","shell.execute_reply.started":"2025-08-07T20:59:24.756771Z","shell.execute_reply":"2025-08-07T20:59:24.756784Z"}},"outputs":[],"execution_count":null}]}